{
    "exp_name": "Catcher_DiffQ_eps_0.1_test",
    "env": "Catcher",
    "agent": "DifferentialQlearningAgent",
    "exp_parameters":
    {
        "num_runs": 1,
        "num_max_steps": 1000
    },
    "env_parameters":
    {
      "grid_size": 10
    },

    "agent_parameters":
    {
        "fixed_parameters":
        {
            "num_states": 4,
            "num_actions": 2,
            "policy_type": "egreedy",
            "epsilon_start": 1.0,
            "epsilon_end": 0.1,
            "epsilon_decay": true,
            "decay_period": 10000,

            "alpha_anneal_factor": 0.9995,
            "alpha_steps_per_anneal": 1000,
            "alpha_end": 0.001,

            "eta_anneal_factor": 0.9995,
            "eta_steps_per_anneal": 1000,

            "hidden_layer_sizes": [5, 5],
            "er_buffer_capacity": 10000,
            "batch_size": 32,
            "steps_per_target_network_update": 10
        },
        "sweep_parameters":
        {
            "alpha": [0.025],
            "eta": [0.5]
        }
    }
}