{
    "exp_name": "Catcher_DiffQ_eps_1-0.1",
    "env": "Catcher",
    "agent": "DifferentialQlearningAgent",
    "exp_parameters":
    {
        "num_runs": 1,
        "num_max_steps": 100000,
        "save_model_params": true
    },
    "env_parameters":
    {
    },

    "agent_parameters":
    {
        "fixed_parameters":
        {
            "policy_type": "egreedy",
            "epsilon_start": 1.0,
            "epsilon_end": 0.1,
            "warmup_steps": 1000,
            "decay_period": 10000,

            "layer_sizes": [4, 5, 5, 2],
            "er_buffer_capacity": 50000,
            "batch_size": 32,
            "steps_per_target_network_update": 1000
        },
        "sweep_parameters":
        {
            "alpha": [0.00025],
            "eta": [0.000005, 0.00005, 0.00125, 0.005, 0.5]
        }
    }
}