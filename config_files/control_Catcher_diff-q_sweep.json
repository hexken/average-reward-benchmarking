{
    "exp_name": "Catcher_DiffQ_eps_1-0.1_sweep",
    "env": "Catcher",
    "agent": "DifferentialQlearningAgent",
    "exp_parameters":
    {
        "num_runs": 30,
        "num_max_steps": 80000,
        "save_model_params": true
    },
    "env_parameters":
    {
    },

    "agent_parameters":
    {
        "fixed_parameters":
        {
            "policy_type": "egreedy",
            "epsilon_start": 1.0,
            "epsilon_end": 0.1,
            "warmup_steps": 1000,
            "decay_period": 4000,

            "layer_sizes": [4, 5, 5, 2],
            "er_buffer_capacity": 80000,
            "batch_size": 32,
            "steps_per_target_network_update": 1000
        },
        "sweep_parameters":
        {
            "alpha": [1e-4, 1e-3, 1e-2, 1e-1],
            "eta": [10, 1, 1e-1, 1e-2]
        }
    }
}